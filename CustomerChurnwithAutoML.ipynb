{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {
     "keep": true,
     "summary": true
    }
   },
   "source": [
    "# Customer Churn Analysis\n",
    "Churn rate, when applied to a customer base, refers to the proportion of contractual customers or subscribers who leave a supplier during a given time period. It is a possible indicator of customer dissatisfaction, cheaper and/or better offers from the competition, more successful sales and/or marketing by the competition, or reasons having to do with the customer life cycle.\n",
    "\n",
    "Churn is closely related to the concept of average customer life time. For example, an annual churn rate of 25 percent implies an average customer life of four years. An annual churn rate of 33 percent implies an average customer life of three years. The churn rate can be minimized by creating barriers which discourage customers to change suppliers (contractual binding periods, use of proprietary technology, value-added services, unique business models, etc.), or through retention activities such as loyalty programs. It is possible to overstate the churn rate, as when a consumer drops the service but then restarts it within the same year. Thus, a clear distinction needs to be made between \"gross churn\", the total number of absolute disconnections, and \"net churn\", the overall loss of subscribers or members. The difference between the two measures is the number of new subscribers or members that have joined during the same period. Suppliers may find that if they offer a loss-leader \"introductory special\", it can lead to a higher churn rate and subscriber abuse, as some subscribers will sign on, let the service lapse, then sign on again to take continuous advantage of current specials. https://en.wikipedia.org/wiki/Churn_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys \n",
    "sys.path.append('model_management')\n",
    "\n",
    "from model_management.sklearn_model import SklearnModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from __future__ import print_function\n",
    "import pandas_profiling\n",
    "\n",
    "# Suppress unwatned warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "\n",
    "# Load our favorite visualization library\n",
    "import os\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "import cufflinks as cf\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "# Sign into Plotly with masked, encrypted API key\n",
    "\n",
    "myPlotlyKey = os.environ['SECRET_ENV_BRETTS_PLOTLY_KEY']\n",
    "py.sign_in(username='bretto777',api_key=myPlotlyKey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load some data\n",
    "churnDF = pd.read_csv('https://trifactapro.s3.amazonaws.com/churn.csv', delimiter=',')\n",
    "churnDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#pandas_profiling.ProfileReport(churnDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnDF[\"Churn\"] = churnDF[\"Churn\"].replace([True, False],[1,0])\n",
    "churnDF[\"Int'l Plan\"] = churnDF[\"Int'l Plan\"].replace([\"no\",\"yes\"],[0,1])\n",
    "churnDF[\"VMail Plan\"] = churnDF[\"VMail Plan\"].replace([\"no\",\"yes\"],[0,1])\n",
    "churnDF.drop([\"State\", \"Area Code\", \"Phone\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {}
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Split data into training and testing frames\n",
    "\n",
    "\n",
    "h2o.init(nthreads=1, max_mem_size=\"768m\")\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, testing = train_test_split(churnDF, train_size=0.8, stratify=churnDF[\"Churn\"], random_state=9)\n",
    "x_train = training.drop([\"Churn\"], axis = 1)\n",
    "y_train = training[\"Churn\"]\n",
    "x_test = testing.drop([\"Churn\"], axis = 1)\n",
    "y_test = testing[\"Churn\"]\n",
    "train = h2o.H2OFrame(python_obj=training)\n",
    "test = h2o.H2OFrame(python_obj=testing)\n",
    "train[\"Churn\"] = train[\"Churn\"].asfactor()\n",
    "test[\"Churn\"] = test[\"Churn\"].asfactor()\n",
    "# Set predictor and response variables\n",
    "y = \"Churn\"\n",
    "x = train.columns\n",
    "x.remove(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbm = GradientBoostingClassifier(n_estimators=200, \n",
    "                                                           learning_rate=.07,\n",
    "                                                           max_depth=4, \n",
    "                                                           random_state=0).fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_gbm = SklearnModel(model=gbm,\n",
    "                     problem_class='binary_classification',\n",
    "                     description='GBM, 275 trees, learning rate .04, max depth 5',\n",
    "                     name=\"GBM-4\",\n",
    "                     y_test = y_test,\n",
    "                     x_test = x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gbm.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gbm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression().fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = SklearnModel(model=lr,\n",
    "                     problem_class='binary_classification',\n",
    "                     description='sklearn logistic regression, default settings',\n",
    "                     name=\"LR-2\",\n",
    "                     y_test = y_test,\n",
    "                     x_test = x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "source": [
    "# Automatic Machine Learning\n",
    "\n",
    "The Automatic Machine Learning (AutoML) function automates the supervised machine learning model training process. The current version of AutoML trains and cross-validates a Random Forest, an Extremely-Randomized Forest, a random grid of Gradient Boosting Machines (GBMs), a random grid of Deep Neural Nets, and a Stacked Ensemble of all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run AutoML until 11 models are built\n",
    "autoModel = H2OAutoML(max_models = 9)\n",
    "autoModel.train(x = x, y = y,\n",
    "          training_frame = train,\n",
    "          validation_frame = test, \n",
    "          leaderboard_frame = test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaders = autoModel.leaderboard\n",
    "leaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "source": [
    "# Variable Importances\n",
    "Below we plot variable importances as reported by the best performing algo in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": true,
     "summary": true
    }
   },
   "outputs": [],
   "source": [
    "importances = h2o.get_model(leaders[2, 0]).varimp(use_pandas=True)\n",
    "importances = importances.loc[:,['variable','relative_importance']].groupby('variable').mean()\n",
    "importances.sort_values(by=\"relative_importance\", ascending=False).iplot(kind='bar', colors='#5AC4F2', theme='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "bestModel = h2o.get_model(leaders[2, 0])\n",
    "plt = bestModel.partial_plot(data=test, cols=[\"Day Mins\",\"CustServ Calls\",\"Day Charge\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {
     "keep": true,
     "summary": false
    }
   },
   "source": [
    "# Best Model vs the Base Learners\n",
    "This plot shows the ROC curves for the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model0 = np.array(h2o.get_model(leaders[0,0]).roc(xval=True))\n",
    "Model1 = np.array(h2o.get_model(leaders[1,0]).roc(xval=True))\n",
    "Model2 = np.array(h2o.get_model(leaders[2,0]).roc(xval=True))\n",
    "Model3 = np.array(h2o.get_model(leaders[3,0]).roc(xval=True))\n",
    "Model4 = np.array(h2o.get_model(leaders[4,0]).roc(xval=True))\n",
    "Model5 = np.array(h2o.get_model(leaders[5,0]).roc(xval=True))\n",
    "Model6 = np.array(h2o.get_model(leaders[6,0]).roc(xval=True))\n",
    "Model7 = np.array(h2o.get_model(leaders[7,0]).roc(xval=True))\n",
    "Model8 = np.array(h2o.get_model(leaders[8,0]).roc(xval=True))\n",
    "Model9 = np.array(h2o.get_model(leaders[9,0]).roc(xval=True))\n",
    "\n",
    "layout = go.Layout(autosize=False, width=725, height=575,  xaxis=dict(title='False Positive Rate', titlefont=dict(family='Arial, sans-serif', size=15, color='grey')), \n",
    "                                                           yaxis=dict(title='True Positive Rate', titlefont=dict(family='Arial, sans-serif', size=15, color='grey')))\n",
    "\n",
    "traceChanceLine = go.Scatter(x = [0,1], y = [0,1], mode = 'lines+markers', name = 'chance', line = dict(color = ('rgb(136, 140, 150)'), width = 4, dash = 'dash'))\n",
    "Model0Trace = go.Scatter(x = Model0[0], y = Model0[1], mode = 'lines', name = 'Model 0', line = dict(color = ('rgb(26, 58, 126)'), width = 3))\n",
    "Model1Trace = go.Scatter(x = Model1[0], y = Model1[1], mode = 'lines', name = 'Model 1', line = dict(color = ('rgb(156, 190, 241))'), width = 1))\n",
    "Model2Trace = go.Scatter(x = Model2[0], y = Model2[1], mode = 'lines', name = 'Model 2', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model3Trace = go.Scatter(x = Model3[0], y = Model3[1], mode = 'lines', name = 'Model 3', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model4Trace = go.Scatter(x = Model4[0], y = Model4[1], mode = 'lines', name = 'Model 4', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model5Trace = go.Scatter(x = Model5[0], y = Model5[1], mode = 'lines', name = 'Model 5', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model6Trace = go.Scatter(x = Model6[0], y = Model6[1], mode = 'lines', name = 'Model 6', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model7Trace = go.Scatter(x = Model7[0], y = Model7[1], mode = 'lines', name = 'Model 7', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model8Trace = go.Scatter(x = Model8[0], y = Model8[1], mode = 'lines', name = 'Model 8', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "Model9Trace = go.Scatter(x = Model9[0], y = Model9[1], mode = 'lines', name = 'Model 9', line = dict(color = ('rgb(156, 190, 241)'), width = 1))\n",
    "\n",
    "fig = go.Figure(data=[Model0Trace,Model1Trace,Model2Trace,Model3Trace,Model4Trace,Model5Trace,Model6Trace,Model8Trace,Model9Trace,traceChanceLine], layout=layout)\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {}
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "outputs": [],
   "source": [
    "cm = h2o.get_model(leaders[1, 0]).confusion_matrix(xval=True)\n",
    "cm = cm.table.as_data_frame()\n",
    "cm\n",
    "confusionMatrix = ff.create_table(cm)\n",
    "confusionMatrix.layout.height=300\n",
    "confusionMatrix.layout.width=800\n",
    "confusionMatrix.layout.font.size=17\n",
    "py.iplot(confusionMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "source": [
    "# Business Impact Matrix\n",
    "\n",
    "Weighting Predictions With a Dollar Value\n",
    "-   Correctly predicting retain: `+$5`\n",
    "-   Correctly predicting churn: `+$75`\n",
    "-   Incorrectly predicting retain: `-$150`\n",
    "-   Incorrectly predicting churn: `-$1.5`\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "outputs": [],
   "source": [
    "CorrectPredictChurn = cm.loc[1,'1']\n",
    "CorrectPredictChurnImpact = 75\n",
    "cm1 = CorrectPredictChurn*CorrectPredictChurnImpact\n",
    "\n",
    "IncorrectPredictChurn = cm.loc[1,'0']\n",
    "IncorrectPredictChurnImpact = -5\n",
    "cm2 = IncorrectPredictChurn*IncorrectPredictChurnImpact\n",
    "\n",
    "IncorrectPredictRetain = cm.loc[0,'1']\n",
    "IncorrectPredictRetainImpact = -150\n",
    "cm3 = IncorrectPredictRetain*IncorrectPredictRetainImpact\n",
    "\n",
    "CorrectPredictRetain = cm.loc[0,'0']\n",
    "CorrectPredictRetainImpact = 5\n",
    "cm4 = IncorrectPredictRetain*CorrectPredictRetainImpact\n",
    "\n",
    "\n",
    "data_matrix = [['Business Impact', '($) Predicted Churn', '($) Predicted Retain', '($) Total'],\n",
    "               ['($) Actual Churn', cm1, cm3, '' ],\n",
    "               ['($) Actual Retain', cm2, cm4, ''],\n",
    "               ['($) Total', cm1+cm2, cm3+cm4, cm1+cm2+cm3+cm4]]\n",
    "\n",
    "impactMatrix = ff.create_table(data_matrix, height_constant=20, hoverinfo='weight')\n",
    "impactMatrix.layout.height=300\n",
    "impactMatrix.layout.width=800\n",
    "impactMatrix.layout.font.size=17\n",
    "py.iplot(impactMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total customers evaluated: 2132\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total value created by the model: $\" + str(cm1+cm2+cm3+cm4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_datascience": {
     "keep": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Total value per customer: $\" +str(round(((cm1+cm2+cm3+cm4)/2132),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "# Save the best model\n",
    "\n",
    "#path = h2o.save_model(model=h2o.get_model(leaders[0, 0]), force=True)\n",
    "#os.rename(h2o.get_model(leaders[0, 0]).model_id, \"AutoML-leader\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#LoadedEnsemble = h2o.load_model(path=\"AutoML-leader\")\n",
    "#print(LoadedEnsemble)"
   ]
  }
 ],
 "metadata": {
  "_datascience": {
   "notebookId": 608,
   "post_id": "AVs_WCYcdxOghr0gw_3H"
  },
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
